# AI対話振り返りメディテーションシステム

**Version:** 2.2 (MVPStreamlit版)  
**Last Updated:** 2025/12/05

「言葉にできないモヤモヤ」を可視化し、就寝前のメンタルヘルスを整えるAIコーチングシステム。

---

## 📚 目次

1. [概要](#概要)
2. [機能](#機能)
3. [ドキュメント](#ドキュメント)
4. [システムアーキテクチャ](#システムアーキテクチャ)
5. [機能要件](#機能要件)
6. [実装要件](#実装要件)
7. [プロジェクト構成](#プロジェクト構成)
8. [技術スタック](#技術スタック)
9. [開発チーム](#開発チーム)
10. [開発ロードマップ](#開発ロードマップ)
11. [注意事項](#注意事項)

---

## 概要

ユーザーの「言葉（テキスト）」だけでなく、「表情（映像）」や「声のトーン（音声）」という非言語情報をマルチモーダルに解析し、ユーザー自身も気づいていない感情の機微を指摘・受容する対話体験を提供します。

### ターゲット体験

- **手軽さ**: ユーザーは就寝前、カメラに向かってその日の出来事を「話す」だけ（タイピング不要）
- **気づき**: 「辛いと言葉では言っているが、少し笑っている」などの矛盾や隠れた感情をAIがフィードバックする
- **記録**: 感情の推移が自動でログ化され、客観的に自分を見つめ直せる

### プロジェクト方針

- **UX優先**: ユーザーの自然な会話を阻害しないよう、リアルタイム映像処理 (`streamlit-webrtc`) と音声入力 (`st.audio_input`) を採用する
- **リソース配慮**: サーバー負荷を考慮し、映像解析は間引き処理を行い、音声解析は軽量な手法を用いる
- **堅牢性**: エラーハンドリングとリソース管理（ファイル削除等）を徹底する

---

## 機能

- 📹 **リアルタイム感情解析**: Webカメラを使用したDeepFaceによる感情認識
- 🎤 **音声認識**: Whisper APIによる音声の文字起こし
- 🤖 **AI対話**: GPT-4o-miniによる共感的なカウンセリング対話
- 📊 **感情の可視化**: 過去の感情推移をグラフで表示
- 💾 **データ保存**: SQLiteによる対話履歴の保存

---

## 📖 ドキュメント

### セットアップ・使用方法

**📚 [MANUAL.md](MANUAL.md)** に詳細な手順を記載しています：

- 🚀 **クイックスタート**: 5分で始められる最短セットアップ手順
- 📝 **環境構築**: 仮想環境の作成からパッケージインストールまで
- 🎯 **使用方法**: アプリの基本的な使い方
- 🔧 **トラブルシューティング**: よくある問題と解決方法

**初心者の方も経験者の方も、まず [MANUAL.md](MANUAL.md) をご覧ください！**

---

## システムアーキテクチャ

### 実行環境

**MVP段階では、Streamlit上のみで動作することを前提とする。**

- **実行環境**: Streamlit Cloud または ローカル環境
- **言語**: Python 3.10+
- **デプロイ**: Streamlitアプリケーションとして単一実行

> **注意**: 本仕様書はMVP版のため、ConoHa VPSなどの外部サーバーは不要。将来的なスケールアップ時に検討する。

### システムフロー図

```
┌─────────────────────────────────────────────────────────────┐
│  フロントエンド: Streamlit                                    │
│  ┌──────────┐    ┌──────────┐    ┌──────────┐              │
│  │ボタン押す│ → │録音/録画  │ → │ボタン離す│              │
│  │ (開始)   │    │          │    │ (終了)   │              │
│  └──────────┘    └──────────┘    └──────────┘              │
│                        ↓                                     │
│              ┌─────────────────┐                            │
│              │ データ: 画像, 音声 │                          │
│              └─────────────────┘                            │
└─────────────────────────────────────────────────────────────┘
                        ↓
┌─────────────────────────────────────────────────────────────┐
│  メイン処理フロー                                              │
│                                                               │
│  ┌──────────────┐         ┌──────────────┐                 │
│  │ 画像処理      │         │ 音声処理      │                 │
│  │              │         │              │                 │
│  │ DeepFace     │         │ Whisper API  │                 │
│  │ 表情認識      │         │ 文字起こし    │                 │
│  └──────┬───────┘         └──────┬───────┘                 │
│         │                        │                          │
│         └──────────┬─────────────┘                          │
│                    ↓                                        │
│         ┌──────────────────────┐                           │
│         │ 統合プロンプト構築     │                           │
│         │ (表情 + 音声) 　　　　　│                           │
│         └──────────┬───────────┘                           │
│                    ↓                                        │
│         ┌──────────────────────┐                           │
│         │   ChatGPT API        │                           │
│         └──────────┬───────────┘                           │
│                    ↓                                        │
│  ┌─────────────────────────────────┐                      │
│  │ 応答する + 質問orさよなら         │                      │
│  │ 一定回くり返し                   │                      │
│  └─────────────────────────────────┘                      │
└─────────────────────────────────────────────────────────────┘
                        ↓
┌─────────────────────────────────────────────────────────────┐
│  できれば - 時間あれば (オプション機能)                        │
│                                                               │
│  ┌──────────────┐         ┌──────────────┐                 │
│  │ トーン分析    │         │ X-Y平面       │                 │
│  │              │         │ 感情プロット   │                 │
│  └──────────────┘         └──────────────┘                 │
└─────────────────────────────────────────────────────────────┘
                        ↓
┌─────────────────────────────────────────────────────────────┐
│  データ保存                                                    │
│                                                               │
│  ┌──────────────────────────────────────┐                   │
│  │  データベース (SQLite)                │                   │
│  │  • ログインユーザー情報                │                   │
│  │  • 日記情報 (会話ログ、感情データ)      │                   │
│  └──────────────────────────────────────┘                   │
└─────────────────────────────────────────────────────────────┘
```

### ハイブリッド処理モデル

リソース制約を回避するため、重い処理を分散させる。

| 処理ブロック | 技術スタック | 実行場所 | 備考 |
|------------|------------|---------|------|
| **フロントエンド** | Streamlit | Streamlit (Local/Cloud) | UI構築および全体の制御 |
| **映像入力** | streamlit-webrtc | ブラウザ ↔ Streamlit | リアルタイム映像通信 |
| **映像解析** | DeepFace, OpenCV | Streamlit (Local) | OpenCV形式に変換して解析 |
| **音声認識** | Whisper API | クラウド (OpenAI) | サーバー負荷軽減のためAPI利用 |
| **対話生成** | GPT-4o-mini | クラウド (OpenAI) | 高速レスポンス・低コスト |
| **データ保存** | SQLite | Streamlit (Local) | ファイルベースの軽量DB |

---

## 機能要件

### ユーザーインターフェース (UI)

#### メイン画面

- **Webカメラ映像表示エリア**: リアルタイム感情ラベル付き
- **録音ボタン**: 「録音開始」→「録音終了（送信）」のトグル式
- **チャットログ表示エリア**: 対話履歴の表示

#### サイドバー

- **ユーザー切り替え**: User A / User B ... の選択
- **過去の感情グラフ表示**: 折れ線グラフによる可視化

### 映像処理ロジック

**実装ファイル**: `modules/video_processor.py`

**使用ライブラリ**: streamlit-webrtc, DeepFace, OpenCV

**処理フロー**:

1. WebRTC経由でフレームを受信
2. OpenCV形式（NumPy配列/BGR）に変換
3. **間引き処理**: サーバー負荷対策として、30フレームに1回 (または1秒に1回) のみ DeepFaceによる推論を実行するロジックを必ず入れること
4. 推論結果（Happy, Sad, Neutral等）をフレーム上に描画し、ブラウザへ返送
5. 最新の感情ステータスを保持し、対話生成時に参照できるようにする

**エラーハンドリング**: 解析エラー時（顔未検出など）は、前回の結果を維持するか "Analyzing..." と表示し、アプリをクラッシュさせないこと (try-except 必須)

### 音声・対話ロジック

**実装ファイル**: `modules/audio_processor.py`

**入力**: `st.audio_input` を使用

**音声認識**: 録音データを一時ファイル保存し、OpenAI Whisper APIへ送信

- **Whisper API**: エラー時は `None` を返し、UI側で「音声認識に失敗しました」と表示できるようにする

**トーン分析**: librosa ライブラリを使用し、負荷の低い `rms` (音量) と `tempo` (話速) の抽出のみに留めること（サーバー負荷を抑えるため）

**クリーンアップ**: 処理完了後、生成した一時音声ファイル (.wav) を **必ず削除** (`os.remove`) する処理を入れること

**プロンプト構築**:

- ユーザー発言 + 検出された表情 + 声のトーン を統合
- System Promptにより「共感的なカウンセラー」として振る舞わせる

### データベース (SQLite)

**実装ファイル**: `modules/database.py`

複雑なセットアップ不要の `sqlite3` を使用。

**テーブル構成 (`logs`)**:

| カラム名 | 型 | 説明 |
|---------|---|------|
| `id` | INTEGER | PRIMARY KEY |
| `user_id` | TEXT | ユーザーID |
| `timestamp` | DATETIME | タイムスタンプ |
| `user_voice_text` | TEXT | 文字起こし結果 |
| `detected_emotion` | TEXT | DeepFace結果 |
| `ai_response` | TEXT | AI返答 |

**インデックス**: テーブル `logs` に `user_id`, `timestamp` のインデックスを作成し、検索を高速化すること

---

## 実装要件

### 映像処理モジュール (`modules/video_processor.py`)

- `streamlit-webrtc` を使用

**DeepFaceによる感情解析**:

- サーバー負荷対策のため、30フレームに1回 (または1秒に1回) のみ解析を実行するロジックを必ず入れること
- 解析エラー時（顔未検出など）は、前回の結果を維持するか "Analyzing..." と表示し、アプリをクラッシュさせないこと (try-except 必須)

### 音声処理モジュール (`modules/audio_processor.py`)

- **Whisper API**: エラー時は `None` を返し、UI側で「音声認識に失敗しました」と表示できるようにする
- **Librosa**: 負荷の低い `rms` (音量) と `tempo` (話速) の抽出のみに留めること
- **クリーンアップ**: 処理完了後、生成した一時音声ファイル (.wav) を **必ず削除** (`os.remove`) する処理を入れること

### データベースモジュール (`modules/database.py`)

- SQLiteを使用
- テーブル `logs` に `user_id`, `timestamp` のインデックスを作成し、検索を高速化すること

### メインUI (`app.py`)

- **ローディング表示**: 音声処理やAPI通信中は、必ず `st.spinner` を使用してユーザーに進行状況を伝えること
- **エラー表示**: API制限やネットワークエラーが発生した場合、`st.error` で分かりやすくメッセージを表示すること
- **セッション管理**: `st.session_state` を活用し、ページリロードしても対話履歴が消えないようにすること

---

## プロジェクト構成

```
ABC_miniproject/
├── app.py                    # メインUIアプリケーション
├── modules/
│   ├── video_processor.py   # 映像処理モジュール
│   ├── audio_processor.py   # 音声処理モジュール
│   └── database.py          # データベースモジュール
├── requirements.txt         # Python依存パッケージ
├── setup.sh                # セットアップスクリプト（macOS/Linux）
├── MANUAL.md               # 初心者向けマニュアル（クイックスタート含む）
├── .env                     # 環境変数（APIキー等）
└── README.md               # プロジェクト説明書
```

---

## 技術スタック

- **Frontend**: Streamlit, streamlit-webrtc
- **Vision**: opencv-python-headless, deepface
- **Audio**: openai (Whisper API), librosa
- **Database**: sqlite3
- **AI**: openai (GPT-4o-mini)

---

## 開発チーム

### メンバー①：テックリード

**担当**: インフラ基盤 & 映像処理コア

**タスク**:

- Streamlit環境のセットアップ
- `video_processor.py` の実装と `app.py` への統合
- DeepFaceがメモリ落ちしないかの負荷テスト

### メンバー②：UI & データ担当（メンバーA）

**担当**: フロントエンド & データベース

**タスク**:

- Streamlitによる画面レイアウト作成
- SQLiteへの保存関数 (`save_log`) と読み込み関数 (`load_logs`) の作成
- 過去データを可視化するグラフの実装 (`st.line_chart`)

### メンバー③：AIロジック担当（メンバーB）

**担当**: API連携 & プロンプトエンジニアリング

**タスク**:

- Whisper API および ChatGPT API を叩く関数の実装
- AIの人格形成（System Promptの調整）
- 「表情と声の情報」をどうAIに伝えるかのロジック検討

---

## 開発ロードマップ

### Phase 1: Hello World (〜12/10)

- サーバー上でカメラが起動し、顔認識枠が表示されること
- 録音した音声がテキスト化されること

### Phase 2: モジュール結合 (〜12/20)

- 映像解析結果と音声テキストを合わせてGPTに送る
- 返答が画面に返ってくる

### Phase 3: UX改善 & 安定化 (〜12/31)

- DB保存の実装
- UIデザインの調整（使いやすさ向上）

### Phase 4: 最終調整 (1月)

- デモ用のシナリオ作成
- 予備機能（Google Cloud連携など）への挑戦（余裕があれば）

### オプション機能（時間があれば実装）

以下の機能は、MVP完了後に検討するオプション機能です。

- **トーン分析**: 音声のトーン（感情的なニュアンス）を詳細に分析
- **X-Y平面感情プロット**: 感情の推移を2次元グラフで可視化
- **Google Cloud連携**: より高度な分析機能の実装

---

## 注意事項

- 本システムはMVP版です
- OpenAI APIの利用にはAPIキーが必要です（有料）
- カメラとマイクへのアクセス許可が必要です
- 初回起動時、DeepFaceモデルのダウンロードに時間がかかる場合があります

---

## ライセンス

[ライセンス情報を記載]
