"""ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ - ã‚¹ãƒ†ãƒƒãƒ—ãƒã‚¤ã‚¹ãƒ†ãƒƒãƒ—ã§è‡ªå‹•é€²è¡Œ"""

import streamlit as st
import streamlit.components.v1 as components
import plotly.graph_objects as go
from datetime import datetime
from utils import init_session_state, get_openai_client
from services.transcription import transcribe_video
from services.ai_chat import generate_ai_response

st.set_page_config(
    page_title="AIå¯¾è©±æŒ¯ã‚Šè¿”ã‚Šãƒ¡ãƒ‡ã‚£ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ MVP",
    page_icon="ğŸ§˜",
    layout="wide",
    initial_sidebar_state="collapsed",  # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‚’æœ€åˆã‹ã‚‰é–‰ã˜ã‚‹
)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
init_session_state()

# ç¾åœ¨ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’ç®¡ç†ï¼ˆ1: æ„Ÿæƒ…å…¥åŠ›, 2: éŒ²ç”»éŒ²éŸ³, 3: å¯¾è©±çµæœï¼‰
if "current_step" not in st.session_state:
    st.session_state["current_step"] = 1

# OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®å–å¾—
client = get_openai_client()

st.title("ğŸ§˜ AIå¯¾è©±æŒ¯ã‚Šè¿”ã‚Šãƒ¡ãƒ‡ã‚£ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆMVPï¼‰")

# ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
steps = ["æ„Ÿæƒ…å…¥åŠ›", "éŒ²ç”»éŒ²éŸ³", "å¯¾è©±çµæœ"]
progress = (st.session_state["current_step"] - 1) / len(steps)
st.progress(
    progress,
    text=f"ã‚¹ãƒ†ãƒƒãƒ— {st.session_state['current_step']}/{len(steps)}: {steps[st.session_state['current_step'] - 1]}",
)

st.markdown("---")

# ============================
# ã‚¹ãƒ†ãƒƒãƒ—1: æ„Ÿæƒ…å…¥åŠ›
# ============================
if st.session_state["current_step"] == 1:
    st.subheader("ã‚¹ãƒ†ãƒƒãƒ—1: ğŸ­ æ„Ÿæƒ…å…¥åŠ›")
    st.markdown("ä»Šã®æ°—æŒã¡ã‚’2æ¬¡å…ƒã®æ„Ÿæƒ…ãƒ—ãƒ­ãƒƒãƒˆã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

    left, right = st.columns([1, 1], gap="large")

    with left:
        st.write("**â‘  ä»Šã®æ„Ÿæƒ…ã‚’å…¥åŠ›ï¼ˆ2Dï¼‰**")

        x = st.slider(
            "Xè»¸ï¼šä¸å¿« â† 0 â†’ å¿«",
            min_value=-1.0,
            max_value=1.0,
            value=float(st.session_state["emotion_coords"][0]),
            step=0.01,
        )
        y = st.slider(
            "Yè»¸ï¼šéè¦šé†’ï¼ˆè½ã¡ç€ãï¼‰ â† 0 â†’ è¦šé†’",
            min_value=-1.0,
            max_value=1.0,
            value=float(st.session_state["emotion_coords"][1]),
            step=0.01,
        )

        if st.button(
            "ã“ã®åº§æ¨™ã§æ±ºå®š / æ¬¡ã¸é€²ã‚€", type="primary", use_container_width=True
        ):
            st.session_state["emotion_coords"] = (float(x), float(y))
            st.session_state["current_step"] = 2
            st.success(f"ä¿å­˜ã—ã¾ã—ãŸ: {st.session_state['emotion_coords']}")
            st.rerun()

    with right:
        st.write("**æ„Ÿæƒ…ãƒ—ãƒ­ãƒƒãƒˆï¼ˆå¯è¦–åŒ–ãƒ»ã‚¯ãƒªãƒƒã‚¯ã§ç§»å‹•ï¼‰**")

        # Plotlyã‚°ãƒ©ãƒ•ä½œæˆ
        fig = go.Figure()

        # èƒŒæ™¯ã‚°ãƒªãƒƒãƒ‰
        for i in range(-1, 2):
            if i != 0:
                fig.add_hline(
                    y=i * 0.5,
                    line_width=0.5,
                    line_color="lightgray",
                    line_dash="dot",
                    opacity=0.3,
                )
                fig.add_vline(
                    x=i * 0.5,
                    line_width=0.5,
                    line_color="lightgray",
                    line_dash="dot",
                    opacity=0.3,
                )

        fig.add_hline(y=0, line_width=2, line_color="black", opacity=0.5)
        fig.add_vline(x=0, line_width=2, line_color="black", opacity=0.5)

        # ç¾åœ¨ã®ç‚¹
        fig.add_trace(
            go.Scatter(
                x=[x],
                y=[y],
                mode="markers",
                marker=dict(size=20, color="red", line=dict(width=3, color="darkred")),
                showlegend=False,
                hovertemplate="<b>ç¾åœ¨ã®åº§æ¨™</b><br>X: %{x:.2f}<br>Y: %{y:.2f}<extra></extra>",
            )
        )

        # ä¿å­˜æ¸ˆã¿ã®ç‚¹
        saved_x, saved_y = st.session_state["emotion_coords"]
        if abs(saved_x - x) > 0.01 or abs(saved_y - y) > 0.01:
            fig.add_trace(
                go.Scatter(
                    x=[saved_x],
                    y=[saved_y],
                    mode="markers",
                    marker=dict(
                        size=15,
                        color="lightblue",
                        line=dict(width=2, color="blue"),
                        opacity=0.7,
                        symbol="circle-open",
                    ),
                    showlegend=False,
                    hovertemplate="<b>ä¿å­˜æ¸ˆã¿åº§æ¨™</b><br>X: %{x:.2f}<br>Y: %{y:.2f}<extra></extra>",
                )
            )

        # ã‚¯ãƒªãƒƒã‚¯å¯èƒ½ãªã‚°ãƒªãƒƒãƒ‰
        grid_step = 0.1
        grid_x_points = [
            i * grid_step
            for i in range(int(-1.0 / grid_step), int(1.0 / grid_step) + 1)
        ]
        grid_y_points = [
            i * grid_step
            for i in range(int(-1.0 / grid_step), int(1.0 / grid_step) + 1)
        ]
        grid_x_all = [gx for gx in grid_x_points for _ in grid_y_points]
        grid_y_all = [gy for gy in grid_y_points for _ in grid_x_points]

        fig.add_trace(
            go.Scatter(
                x=grid_x_all,
                y=grid_y_all,
                mode="markers",
                marker=dict(size=8, opacity=0.01, color="gray"),
                showlegend=False,
                hoverinfo="skip",
            )
        )

        fig.update_layout(
            xaxis=dict(
                range=[-1.1, 1.1], title="Pleasure (ä¸å¿« â† 0 â†’ å¿«)", zeroline=False
            ),
            yaxis=dict(
                range=[-1.1, 1.1],
                title="Arousal (éè¦šé†’ â† 0 â†’ è¦šé†’)",
                zeroline=False,
                scaleanchor="x",
                scaleratio=1,
            ),
            title="Current Emotion Point (ã‚°ãƒ©ãƒ•ä¸Šã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ç§»å‹•)",
            width=500,
            height=500,
            dragmode="select",
            hovermode="closest",
            plot_bgcolor="white",
            paper_bgcolor="white",
        )

        selection = st.plotly_chart(
            fig, use_container_width=True, on_select="rerun", key="emotion_plot"
        )

        if selection and hasattr(selection, "selection") and selection.selection.points:
            try:
                for point_data in selection.selection.points:
                    if len(point_data) >= 2:
                        clicked_x = max(-1.0, min(1.0, float(point_data[0])))
                        clicked_y = max(-1.0, min(1.0, float(point_data[1])))
                        st.session_state["emotion_coords"] = (clicked_x, clicked_y)
                        st.success(
                            f"åº§æ¨™ã‚’æ›´æ–°ã—ã¾ã—ãŸ: ({clicked_x:.2f}, {clicked_y:.2f})"
                        )
                        st.rerun()
                        break
            except (AttributeError, IndexError, ValueError):
                pass

        st.info(
            f"ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ç¾åœ¨å€¤: (x, y)=({x:.2f}, {y:.2f}) / ä¿å­˜æ¸ˆã¿: {st.session_state['emotion_coords']}"
        )

# ============================
# ã‚¹ãƒ†ãƒƒãƒ—2: éŒ²ç”»éŒ²éŸ³
# ============================
elif st.session_state["current_step"] == 2:
    st.subheader("ã‚¹ãƒ†ãƒƒãƒ—2: ğŸ“¹ éŒ²ç”»ãƒ»éŒ²éŸ³")
    st.markdown("ã‚«ãƒ¡ãƒ©ã¨ãƒã‚¤ã‚¯ã‚’ä½¿ã£ã¦ã€å‹•ç”»ã¨éŸ³å£°ã‚’åŒæ™‚ã«éŒ²ç”»ã—ã¾ã™ã€‚")

    left2, right2 = st.columns([1, 1], gap="large")

    with left2:
        st.write("**â‘¡ åéŒ²ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«**")

        if not st.session_state["is_recording"]:
            if st.button("â–¶ï¸ ã‚¹ã‚¿ãƒ¼ãƒˆ", use_container_width=True):
                st.session_state["is_recording"] = True
                st.session_state["recording_started_at"] = datetime.now().isoformat(
                    timespec="seconds"
                )
                st.session_state["video_buffer"] = None
                st.session_state["audio_buffer"] = None
                st.session_state["captured_frame"] = None
                st.session_state["captured_audio"] = None
                st.success("åéŒ²ã‚’é–‹å§‹ã—ã¾ã—ãŸ")
                st.rerun()
        else:
            if st.button("â¹ï¸ ã‚¹ãƒˆãƒƒãƒ—ï¼ˆåéŒ²å®Œäº†ï¼‰", use_container_width=True):
                st.session_state["is_recording"] = False

                if st.session_state["recorded_video_data"] is not None:
                    st.session_state["video_buffer"] = st.session_state[
                        "recorded_video_data"
                    ]
                    st.session_state["audio_buffer"] = st.session_state[
                        "recorded_video_data"
                    ]
                else:
                    if st.session_state["captured_frame"] is not None:
                        st.session_state["video_buffer"] = st.session_state[
                            "captured_frame"
                        ].getvalue()
                    else:
                        st.session_state["video_buffer"] = b""
                    if st.session_state["captured_audio"] is not None:
                        st.session_state["audio_buffer"] = st.session_state[
                            "captured_audio"
                        ].getvalue()
                    else:
                        st.session_state["audio_buffer"] = b""

                st.success("åéŒ²ã‚’åœæ­¢ã—ã¾ã—ãŸã€‚æ–‡å­—èµ·ã“ã—å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™...")

                # éŒ²ç”»ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã€æ–‡å­—èµ·ã“ã—å‡¦ç†ã‚’è‡ªå‹•å®Ÿè¡Œ
                if (
                    st.session_state["recorded_video_data"] is not None
                    and client is not None
                    and "OPENAI_API_KEY" in st.secrets
                ):
                    with st.status(
                        "éŒ²ç”»ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰éŸ³å£°ã‚’æŠ½å‡ºã—ã¦æ–‡å­—èµ·ã“ã—ä¸­...", expanded=True
                    ) as status:
                        try:
                            st.write("å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...")
                            st.write(
                                "Whisper APIã«é€ä¿¡ä¸­...ï¼ˆå‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰éŸ³å£°ã‚’æŠ½å‡ºï¼‰"
                            )
                            st.session_state["transcription_status"] = "processing"

                            # ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹ã‚’å‘¼ã³å‡ºã—
                            transcription_text, transcription_status = transcribe_video(
                                st.session_state["recorded_video_data"], client
                            )

                            if transcription_status == "completed":
                                st.session_state["transcription_result"] = (
                                    transcription_text
                                )
                                st.session_state["transcription_status"] = "completed"
                                status.update(
                                    label="æ–‡å­—èµ·ã“ã—å®Œäº†ï¼",
                                    state="complete",
                                    expanded=False,
                                )
                                # æ–‡å­—èµ·ã“ã—ãŒå®Œäº†ã—ãŸã‚‰è‡ªå‹•çš„ã«æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¸ï¼ˆã“ã“ã§é·ç§»ï¼‰
                                st.session_state["current_step"] = 3
                            else:
                                st.session_state["transcription_status"] = "error"
                                st.error("æ–‡å­—èµ·ã“ã—å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
                                status.update(label="ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ", state="error")
                        except Exception as e:
                            st.session_state["transcription_status"] = "error"
                            st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
                            status.update(label="ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ", state="error")

                    # ã‚¹ãƒ†ãƒƒãƒ—é·ç§»å¾Œã€rerun
                    if st.session_state["transcription_status"] == "completed":
                        st.rerun()
                else:
                    st.warning(
                        "éŒ²ç”»ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã¾ãŸã¯APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
                    )

                st.rerun()

        if st.session_state["is_recording"]:
            st.warning(
                f"ğŸ”´ åéŒ²ã‚»ãƒƒã‚·ãƒ§ãƒ³é–‹å§‹ä¸­â€¦ï¼ˆé–‹å§‹æ™‚åˆ»: {st.session_state['recording_started_at']}ï¼‰"
            )
        else:
            st.success("â¸ï¸ åœæ­¢ä¸­")

    with right2:
        st.write("**â‘¢ éŒ²ç”»ãƒ»éŒ²éŸ³**")

        if st.session_state["is_recording"]:
            st.info(
                "ğŸ“¹ ä¸‹ã®éŒ²ç”»UIã§éŒ²ç”»ã‚’é–‹å§‹ã—ã¦ãã ã•ã„ã€‚ã‚«ãƒ¡ãƒ©ã¨ãƒã‚¤ã‚¯ãŒåŒæ™‚ã«èµ·å‹•ã—ã¾ã™ã€‚"
            )

            html_code = """
            <!DOCTYPE html>
            <html>
            <head>
                <meta charset="UTF-8">
                <style>
                    body { font-family: Arial, sans-serif; padding: 10px; }
                    #videoPreview { width: 100%; max-width: 640px; border: 2px solid #ddd; border-radius: 8px; }
                    #recordBtn, #stopBtn { padding: 10px 20px; font-size: 16px; margin: 5px; border-radius: 5px; border: none; cursor: pointer; }
                    #recordBtn { background-color: #ff4444; color: white; }
                    #recordBtn:hover { background-color: #cc0000; }
                    #stopBtn { background-color: #666; color: white; }
                    #stopBtn:hover { background-color: #444; }
                    #stopBtn:disabled { background-color: #ccc; cursor: not-allowed; }
                    .recording-indicator { display: inline-block; width: 12px; height: 12px; background-color: #ff4444; border-radius: 50%; animation: pulse 1.5s infinite; margin-right: 8px; }
                    @keyframes pulse { 0%, 100% { opacity: 1; } 50% { opacity: 0.5; } }
                    #status { margin-top: 10px; padding: 10px; border-radius: 5px; }
                    .status-recording { background-color: #ffe6e6; color: #cc0000; }
                    .status-ready { background-color: #e6f3ff; color: #0066cc; }
                </style>
            </head>
            <body>
                <video id="videoPreview" autoplay muted playsinline></video>
                <div style="margin-top: 10px;">
                    <button id="recordBtn" onclick="startRecording()">ğŸ”´ éŒ²ç”»é–‹å§‹</button>
                    <button id="stopBtn" onclick="stopRecording()" disabled>â¹ éŒ²ç”»åœæ­¢</button>
                </div>
                <div id="status" class="status-ready">æº–å‚™å®Œäº†</div>
                <script>
                    let mediaRecorder;
                    let recordedChunks = [];
                    let stream;
                    const videoPreview = document.getElementById('videoPreview');
                    const recordBtn = document.getElementById('recordBtn');
                    const stopBtn = document.getElementById('stopBtn');
                    const statusDiv = document.getElementById('status');

                    async function startRecording() {
                        try {
                            stream = await navigator.mediaDevices.getUserMedia({
                                video: { width: { ideal: 1280 }, height: { ideal: 720 }, facingMode: 'user' },
                                audio: { echoCancellation: true, noiseSuppression: true }
                            });
                            videoPreview.srcObject = stream;
                            const options = { mimeType: 'video/webm;codecs=vp8,opus', videoBitsPerSecond: 2500000 };
                            if (!MediaRecorder.isTypeSupported(options.mimeType)) {
                                options.mimeType = 'video/webm';
                            }
                            mediaRecorder = new MediaRecorder(stream, options);
                            recordedChunks = [];
                            mediaRecorder.ondataavailable = (event) => {
                                if (event.data && event.data.size > 0) {
                                    recordedChunks.push(event.data);
                                }
                            };
                            mediaRecorder.onstop = () => {
                                const blob = new Blob(recordedChunks, { type: 'video/webm' });
                                const url = URL.createObjectURL(blob);
                                const a = document.createElement('a');
                                a.href = url;
                                a.download = 'recording_' + new Date().getTime() + '.webm';
                                document.body.appendChild(a);
                                a.click();
                                document.body.removeChild(a);
                                URL.revokeObjectURL(url);
                                const reader = new FileReader();
                                reader.onloadend = () => {
                                    const base64data = reader.result;
                                    sessionStorage.setItem('recorded_video', base64data);
                                    window.parent.postMessage({type: 'recording_complete'}, '*');
                                };
                                reader.readAsDataURL(blob);
                                stream.getTracks().forEach(track => track.stop());
                                videoPreview.srcObject = null;
                            };
                            mediaRecorder.start(1000);
                            recordBtn.disabled = true;
                            stopBtn.disabled = false;
                            statusDiv.innerHTML = '<span class="recording-indicator"></span>éŒ²ç”»ä¸­...';
                            statusDiv.className = 'status-recording';
                        } catch (err) {
                            console.error('Error:', err);
                            statusDiv.textContent = 'ã‚¨ãƒ©ãƒ¼: ' + err.message;
                        }
                    }
                    function stopRecording() {
                        if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                            mediaRecorder.stop();
                            recordBtn.disabled = false;
                            stopBtn.disabled = true;
                            statusDiv.textContent = 'éŒ²ç”»ã‚’åœæ­¢ã—ã¾ã—ãŸã€‚ãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ä¸­...';
                            statusDiv.className = 'status-ready';
                        }
                    }
                </script>
            </body>
            </html>
            """

            components.html(html_code, height=500)
            st.success(
                "âœ… éŒ²ç”»ãŒå®Œäº†ã™ã‚‹ã¨ã€è‡ªå‹•çš„ã«å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ.webmå½¢å¼ï¼‰ãŒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã™ã€‚"
            )
        else:
            st.info("åéŒ²ã‚’é–‹å§‹ã™ã‚‹ã¨ã€ã“ã“ã«ã‚«ãƒ¡ãƒ©/éŸ³å£°ã®å…¥åŠ›UIãŒå‡ºã¾ã™ã€‚")

        # æ–‡å­—èµ·ã“ã—ãŒå®Œäº†ã—ã¦ã„ã‚‹å ´åˆã€æ‰‹å‹•ã§æ¬¡ã¸é€²ã‚€ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
        if st.session_state.get("transcription_status") == "completed":
            st.markdown("---")
            if st.button(
                "âœ… æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã¸ï¼ˆå¯¾è©±çµæœï¼‰",
                type="primary",
                use_container_width=True,
                key="next_to_step3",
            ):
                st.session_state["current_step"] = 3
                st.rerun()

# ============================
# ã‚¹ãƒ†ãƒƒãƒ—3: å¯¾è©±çµæœ
# ============================
elif st.session_state["current_step"] == 3:
    st.subheader("ã‚¹ãƒ†ãƒƒãƒ—3: ğŸ’¬ å¯¾è©±ãƒ»çµæœ")
    st.markdown("æ–‡å­—èµ·ã“ã—çµæœã¨AIå¿œç­”ã‚’ç¢ºèªã§ãã¾ã™ã€‚")

    # æ–‡å­—èµ·ã“ã—çµæœã®è¡¨ç¤º
    if st.session_state["transcription_result"]:
        st.markdown("---")
        st.subheader("ğŸ“ æ–‡å­—èµ·ã“ã—çµæœ")
        if st.session_state["transcription_status"] == "completed":
            st.success(st.session_state["transcription_result"])

            # è‡ªå‹•çš„ã«AIå¿œç­”ã‚’ç”Ÿæˆï¼ˆã¾ã ç”Ÿæˆã•ã‚Œã¦ã„ãªã„å ´åˆï¼‰
            if (
                client is not None
                and "OPENAI_API_KEY" in st.secrets
                and st.session_state["ai_response"] is None
            ):
                with st.spinner("AIå¿œç­”ã‚’è‡ªå‹•ç”Ÿæˆä¸­..."):
                    try:
                        # ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹ã‚’å‘¼ã³å‡ºã—
                        ai_response, response_status = generate_ai_response(
                            st.session_state["transcription_result"],
                            st.session_state["emotion_coords"],
                            face_emotion=None,  # å°†æ¥å®Ÿè£…ç”¨
                            client=client,
                        )

                        if response_status == "completed":
                            st.session_state["ai_response"] = ai_response

                            # å¯¾è©±å±¥æ­´ã«è¿½åŠ 
                            st.session_state["conversation_history"].append(
                                {
                                    "transcription": st.session_state[
                                        "transcription_result"
                                    ],
                                    "emotion": st.session_state["emotion_coords"],
                                    "ai_response": st.session_state["ai_response"],
                                    "timestamp": datetime.now().isoformat(),
                                }
                            )

                            st.rerun()
                        else:
                            st.error("AIå¿œç­”ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
                    except Exception as e:
                        st.error(f"AIå¿œç­”ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            elif (
                client is not None
                and "OPENAI_API_KEY" in st.secrets
                and st.session_state["ai_response"] is not None
            ):
                if st.button("ğŸ”„ AIå¿œç­”ã‚’å†ç”Ÿæˆ", type="secondary"):
                    st.session_state["ai_response"] = None
                    st.rerun()
        elif st.session_state["transcription_status"] == "error":
            st.error("æ–‡å­—èµ·ã“ã—å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")

    # AIå¿œç­”ã®è¡¨ç¤º
    if st.session_state["ai_response"]:
        st.markdown("---")
        st.subheader("ğŸ’¬ AIå¿œç­”")
        st.info(st.session_state["ai_response"])

    # å¯¾è©±å±¥æ­´ã®è¡¨ç¤º
    if st.session_state["conversation_history"]:
        st.markdown("---")
        st.subheader("ğŸ“š å¯¾è©±å±¥æ­´")
        for i, conv in enumerate(reversed(st.session_state["conversation_history"])):
            with st.expander(
                f"å¯¾è©± {len(st.session_state['conversation_history']) - i} - {conv.get('timestamp', '')[:10]}"
            ):
                st.write(f"**æ„Ÿæƒ…åº§æ¨™:** {conv['emotion']}")
                st.write(f"**ã‚ãªãŸ:** {conv['transcription']}")
                st.write(f"**AI:** {conv['ai_response']}")

    # æœ€åˆã‹ã‚‰ã‚„ã‚Šç›´ã™ãƒœã‚¿ãƒ³
    st.markdown("---")
    if st.button("ğŸ”„ æœ€åˆã‹ã‚‰ã‚„ã‚Šç›´ã™", type="primary", use_container_width=True):
        st.session_state["current_step"] = 1
        st.session_state["is_recording"] = False
        st.session_state["transcription_result"] = None
        st.session_state["transcription_status"] = "idle"
        st.session_state["ai_response"] = None
        st.rerun()
