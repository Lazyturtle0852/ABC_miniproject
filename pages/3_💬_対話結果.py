"""ãƒšãƒ¼ã‚¸3: å¯¾è©±ãƒ»çµæœ"""

import streamlit as st
from datetime import datetime
from utils import init_session_state, get_openai_client

st.set_page_config(page_title="å¯¾è©±çµæœ", layout="wide")

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
init_session_state()

# OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®å–å¾—
client = get_openai_client()

st.title("ğŸ’¬ å¯¾è©±ãƒ»çµæœ")

st.markdown("æ–‡å­—èµ·ã“ã—çµæœã¨AIå¿œç­”ã‚’ç¢ºèªã§ãã¾ã™ã€‚")


# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰é–¢æ•°
def build_conversation_prompt(transcription_text, emotion_coords):
    """æ–‡å­—èµ·ã“ã—çµæœã¨æ„Ÿæƒ…ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰"""
    x, y = emotion_coords

    # æ„Ÿæƒ…ã®èª¬æ˜ã‚’ç”Ÿæˆ
    if x > 0.5:
        pleasure_desc = "éå¸¸ã«å¿«"
    elif x > 0:
        pleasure_desc = "ã‚„ã‚„å¿«"
    elif x > -0.5:
        pleasure_desc = "ã‚„ã‚„ä¸å¿«"
    else:
        pleasure_desc = "éå¸¸ã«ä¸å¿«"

    if y > 0.5:
        arousal_desc = "éå¸¸ã«è¦šé†’"
    elif y > 0:
        arousal_desc = "ã‚„ã‚„è¦šé†’"
    elif y > -0.5:
        arousal_desc = "ã‚„ã‚„è½ã¡ç€ã"
    else:
        arousal_desc = "éå¸¸ã«è½ã¡ç€ã"

    system_prompt = """ã‚ãªãŸã¯ãƒ¡ãƒ³ã‚¿ãƒ«ãƒ˜ãƒ«ã‚¹ã‚±ã‚¢ã®å°‚é–€å®¶ã§ã™ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„Ÿæƒ…çŠ¶æ…‹ã‚’ç†è§£ã—ã€å…±æ„Ÿçš„ã§ã‚µãƒãƒ¼ãƒˆçš„ãªå¯¾è©±ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®æ„Ÿæƒ…ã«å¯„ã‚Šæ·»ã„ãªãŒã‚‰ã€é©åˆ‡ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚„è³ªå•ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚"""

    user_prompt = f"""ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒè©±ã—ãŸå†…å®¹ï¼š
ã€Œ{transcription_text}ã€

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ç¾åœ¨ã®æ„Ÿæƒ…çŠ¶æ…‹ï¼š
- å¿«/ä¸å¿«è»¸ï¼ˆXè»¸ï¼‰: {x:.2f} ({pleasure_desc})
- è¦šé†’/è½ã¡ç€ãè»¸ï¼ˆYè»¸ï¼‰: {y:.2f} ({arousal_desc})

ã“ã®æ„Ÿæƒ…çŠ¶æ…‹ã¨è©±ã—ãŸå†…å®¹ã‚’è¸ã¾ãˆã¦ã€é©åˆ‡ãªå¿œç­”ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚"""

    return system_prompt, user_prompt


# æ–‡å­—èµ·ã“ã—çµæœã®è¡¨ç¤º
if st.session_state["transcription_result"]:
    st.markdown("---")
    st.subheader("ğŸ“ æ–‡å­—èµ·ã“ã—çµæœ")
    if st.session_state["transcription_status"] == "completed":
        st.success(st.session_state["transcription_result"])

        # è‡ªå‹•çš„ã«AIå¿œç­”ã‚’ç”Ÿæˆï¼ˆã¾ã ç”Ÿæˆã•ã‚Œã¦ã„ãªã„å ´åˆï¼‰
        if (
            client is not None
            and "OPENAI_API_KEY" in st.secrets
            and st.session_state["ai_response"] is None
        ):
            with st.spinner("AIå¿œç­”ã‚’è‡ªå‹•ç”Ÿæˆä¸­..."):
                try:
                    system_prompt, user_prompt = build_conversation_prompt(
                        st.session_state["transcription_result"],
                        st.session_state["emotion_coords"],
                    )

                    response = client.chat.completions.create(
                        model="gpt-4o-mini",
                        messages=[
                            {"role": "system", "content": system_prompt},
                            {"role": "user", "content": user_prompt},
                        ],
                        temperature=0.7,
                    )

                    st.session_state["ai_response"] = response.choices[
                        0
                    ].message.content

                    # å¯¾è©±å±¥æ­´ã«è¿½åŠ 
                    st.session_state["conversation_history"].append(
                        {
                            "transcription": st.session_state["transcription_result"],
                            "emotion": st.session_state["emotion_coords"],
                            "ai_response": st.session_state["ai_response"],
                            "timestamp": datetime.now().isoformat(),
                        }
                    )

                    st.rerun()
                except Exception as e:
                    st.error(f"GPT APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {e}")

        # æ—¢ã«AIå¿œç­”ãŒç”Ÿæˆã•ã‚Œã¦ã„ã‚‹å ´åˆã€æ‰‹å‹•ã§å†ç”Ÿæˆã§ãã‚‹ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
        elif (
            client is not None
            and "OPENAI_API_KEY" in st.secrets
            and st.session_state["ai_response"] is not None
        ):
            if st.button("ğŸ”„ AIå¿œç­”ã‚’å†ç”Ÿæˆ", type="secondary"):
                st.session_state["ai_response"] = None
                st.rerun()
    elif st.session_state["transcription_status"] == "error":
        st.error("æ–‡å­—èµ·ã“ã—å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")

# AIå¿œç­”ã®è¡¨ç¤º
if st.session_state["ai_response"]:
    st.markdown("---")
    st.subheader("ğŸ’¬ AIå¿œç­”")
    st.info(st.session_state["ai_response"])

# å¯¾è©±å±¥æ­´ã®è¡¨ç¤º
if st.session_state["conversation_history"]:
    st.markdown("---")
    st.subheader("ğŸ“š å¯¾è©±å±¥æ­´")
    for i, conv in enumerate(reversed(st.session_state["conversation_history"])):
        with st.expander(
            f"å¯¾è©± {len(st.session_state['conversation_history']) - i} - {conv.get('timestamp', '')[:10]}"
        ):
            st.write(f"**æ„Ÿæƒ…åº§æ¨™:** {conv['emotion']}")
            st.write(f"**ã‚ãªãŸ:** {conv['transcription']}")
            st.write(f"**AI:** {conv['ai_response']}")
else:
    st.markdown("---")
    st.info(
        "ã¾ã å¯¾è©±å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“ã€‚éŒ²ç”»ãƒ»éŒ²éŸ³ãƒšãƒ¼ã‚¸ã§éŒ²ç”»ã—ã€æ–‡å­—èµ·ã“ã—çµæœãŒè¡¨ç¤ºã•ã‚ŒãŸã‚‰ã€ã“ã“ã§AIå¿œç­”ã‚’ç”Ÿæˆã§ãã¾ã™ã€‚"
    )

# æ ¼ç´æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
st.markdown("---")
st.subheader("æ ¼ç´æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ï¼ˆå‚ç…§ç¢ºèªï¼‰")

video_buffer = st.session_state["video_buffer"]
audio_buffer = st.session_state["audio_buffer"]

st.write(f"- emotion_coords: `{st.session_state['emotion_coords']}`")
st.write(
    f"- video_buffer: `{None if video_buffer is None else (str(len(video_buffer)) + ' bytes')}`"
)
st.write(
    f"- audio_buffer: `{None if audio_buffer is None else (str(len(audio_buffer)) + ' bytes')}`"
)
st.write(
    f"- transcription_result: `{st.session_state['transcription_result'] if st.session_state['transcription_result'] else 'None'}`"
)
st.write(f"- transcription_status: `{st.session_state['transcription_status']}`")

# ãƒ‡ãƒãƒƒã‚°è¡¨ç¤º
with st.expander("ãƒ‡ãƒãƒƒã‚°ï¼šsession_stateã‚’è¦‹ã‚‹"):
    st.json(
        {
            "emotion_coords": st.session_state["emotion_coords"],
            "is_recording": st.session_state["is_recording"],
            "recording_started_at": st.session_state["recording_started_at"],
            "video_buffer_len": None if video_buffer is None else len(video_buffer),
            "audio_buffer_len": None if audio_buffer is None else len(audio_buffer),
            "captured_frame": "set"
            if st.session_state["captured_frame"] is not None
            else None,
            "captured_audio": "set"
            if st.session_state["captured_audio"] is not None
            else None,
            "transcription_result": st.session_state["transcription_result"],
            "transcription_status": st.session_state["transcription_status"],
            "conversation_history_count": len(st.session_state["conversation_history"]),
        }
    )
