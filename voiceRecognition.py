import streamlit as st
from openai import OpenAI
import os
from dotenv import load_dotenv

load_dotenv()


def main():
    st.set_page_config(page_title="é«˜è¦–èªæ€§ãƒ»éŸ³å£°èªè­˜ãƒ†ã‚¹ãƒˆ", layout="centered")

    # --- ã‚«ã‚¹ã‚¿ãƒ CSSã§UIã‚’ãƒªãƒƒãƒã«ã™ã‚‹ ---
    st.markdown(
        """
        <style>
        .status-box {
            padding: 20px;
            border-radius: 15px;
            text-align: center;
            margin-bottom: 20px;
            border: 2px solid #ddd;
        }
        .recording-active {
            background-color: #ffebee;
            border-color: #ff1744;
            color: #d32f2f;
            animation: pulse 2s infinite;
        }
        .standby {
            background-color: #f5f5f5;
            color: #616161;
        }
        @keyframes pulse {
            0% { box-shadow: 0 0 0 0 rgba(255, 23, 68, 0.4); }
            70% { box-shadow: 0 0 0 20px rgba(255, 23, 68, 0); }
            100% { box-shadow: 0 0 0 0 rgba(255, 23, 68, 0); }
        }
        </style>
    """,
        unsafe_allow_html=True,
    )

    st.title("ğŸ™ï¸ éŸ³å£°èªè­˜ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—")

    # 1. APIæº–å‚™
    client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

    # 2. çŠ¶æ…‹è¡¨ç¤ºãƒ‘ãƒãƒ«
    # éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã‹ã©ã†ã‹ã§è¡¨ç¤ºã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹
    audio_data = st.audio_input("ã“ã“ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦éŒ²éŸ³ã‚’é–‹å§‹/åœæ­¢ã—ã¦ãã ã•ã„")

    if audio_data is None:
        # å¾…æ©Ÿä¸­ï¼ˆã‚°ãƒ¬ãƒ¼ï¼‰
        st.markdown(
            """
            <div class="status-box standby">
                <h2 style="margin:0;">âšªï¸ å¾…æ©Ÿä¸­</h2>
                <p>ãƒã‚¤ã‚¯ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã¨éŒ²éŸ³ãŒå§‹ã¾ã‚Šã¾ã™</p>
            </div>
        """,
            unsafe_allow_html=True,
        )
    else:
        # ãƒ‡ãƒ¼ã‚¿å—ä¿¡å¾Œï¼ˆèµ¤ï¼‰
        st.markdown(
            """
            <div class="status-box recording-active">
                <h2 style="margin:0;">ğŸ”´ éŸ³å£°å—ä¿¡å®Œäº†</h2>
                <p>æ–‡å­—èµ·ã“ã—å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™...</p>
            </div>
        """,
            unsafe_allow_html=True,
        )

    # 3. ãƒ¡ã‚¤ãƒ³å‡¦ç†
    if audio_data is not None:
        with st.status("AIè§£æä¸­...", expanded=True) as status:
            st.write("éŸ³å£°ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...")

            # ä¸€æ™‚ä¿å­˜
            temp_file = "temp_recording.wav"
            with open(temp_file, "wb") as f:
                f.write(audio_data.read())

            try:
                st.write("Whisper APIã«é€ä¿¡ä¸­...")
                with open(temp_file, "rb") as f:
                    response = client.audio.transcriptions.create(
                        model="whisper-1", file=f, language="ja"
                    )

                st.session_state.text_result = response.text
                status.update(label="è§£æå®Œäº†ï¼", state="complete", expanded=False)

            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
                status.update(label="ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ", state="error")
            finally:
                if os.path.exists(temp_file):
                    os.remove(temp_file)

        # çµæœè¡¨ç¤º
        if "text_result" in st.session_state:
            st.markdown("---")
            st.subheader("ğŸ“ æ–‡å­—èµ·ã“ã—çµæœ")
            st.success(st.session_state.text_result)

            # ãƒªã‚»ãƒƒãƒˆãƒœã‚¿ãƒ³
            if st.button("ã‚‚ã†ä¸€åº¦éŒ²éŸ³ã™ã‚‹"):
                del st.session_state.text_result
                st.rerun()

    # --- éŒ²éŸ³ãŒèµ·å‹•ã—ãªã„äººã¸ã®ã‚¬ã‚¤ãƒ‰ ---
    with st.expander("âš ï¸ éŒ²éŸ³ãƒœã‚¿ãƒ³ãŒåå¿œã—ãªã„å ´åˆã¯ã“ã¡ã‚‰"):
        st.warning("ãƒ–ãƒ©ã‚¦ã‚¶ã®è¨­å®šã§ãƒã‚¤ã‚¯ãŒè¨±å¯ã•ã‚Œã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        st.markdown("""
        1. **ã‚¢ãƒ‰ãƒ¬ã‚¹ãƒãƒ¼ã‚’ç¢ºèª**: å·¦ä¸Šã®ã€Œéµãƒãƒ¼ã‚¯ã€ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã€Œãƒã‚¤ã‚¯ã€ãŒè¨±å¯ã‹ãƒã‚§ãƒƒã‚¯ã€‚
        2. **URLã‚’ç¢ºèª**: localhost:8501 ã«ãªã£ã¦ã„ã¾ã™ã‹ï¼Ÿï¼ˆ`127.0.0.1`ã ã¨å‹•ã‹ãªã„å ´åˆãŒã‚ã‚Šã¾ã™ï¼‰
        3. **å†èª­ã¿è¾¼ã¿**: è¨­å®šã‚’å¤‰ãˆãŸã‚‰ãƒšãƒ¼ã‚¸ã‚’æ›´æ–°ã—ã¦ãã ã•ã„ã€‚
        """)


if __name__ == "__main__":
    main()
